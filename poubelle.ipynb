{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7b8d639",
   "metadata": {},
   "source": [
    "# DÃ©tection de Poubelles Pleines/Vides avec YOLOv9\n",
    "\n",
    "Ce notebook implÃ©mente un modÃ¨le de dÃ©tection d'objets pour prÃ©dire si une poubelle est pleine ou vide."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce92a011",
   "metadata": {},
   "source": [
    "## 3. Import des bibliothÃ¨ques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e024d74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c512e3",
   "metadata": {},
   "source": [
    "## 4. VÃ©rification de la structure du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ef7fe759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset tÃ©lÃ©chargÃ© dans: dataset_detection_poubelle\n",
      "\n",
      "Fichier de configuration: dataset_detection_poubelle\\data.yaml\n",
      "train: train/images\n",
      "val: valid/images\n",
      "test: test/images\n",
      "\n",
      "nc: 2\n",
      "names: ['poubelle_pleine', 'poubelle_vide']\n",
      "\n",
      "roboflow:\n",
      "  workspace: poubelledetection\n",
      "  project: detection_poubelle-6b1qv\n",
      "  version: 1\n",
      "  license: CC BY 4.0\n",
      "  url: https://universe.roboflow.com/poubelledetection/detection_poubelle-6b1qv/dataset/1\n"
     ]
    }
   ],
   "source": [
    "# Trouver le chemin du dataset tÃ©lÃ©chargÃ©\n",
    "dataset_path = \"dataset_detection_poubelle\"\n",
    "data_yaml = os.path.join(dataset_path, \"data.yaml\")\n",
    "\n",
    "\n",
    "print(f\"Dataset tÃ©lÃ©chargÃ© dans: {dataset_path}\")\n",
    "# VÃ©rifier le fichier data.yaml\n",
    "data_yaml = os.path.join(dataset_path, \"data.yaml\")\n",
    "print(f\"\\nFichier de configuration: {data_yaml}\")\n",
    "\n",
    "# Afficher le contenu du fichier data.yaml\n",
    "if os.path.exists(data_yaml):\n",
    "    with open(data_yaml, 'r') as f:\n",
    "        print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af352df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š RÃ©partition des donnÃ©es :\n",
      "\n",
      "train : 226 images\n",
      "valid : 32 images\n",
      "test : 17 images\n"
     ]
    }
   ],
   "source": [
    "splits = [\"train\", \"valid\", \"test\"]\n",
    "extensions = (\".jpg\", \".jpeg\", \".png\")\n",
    "\n",
    "print(\"ğŸ“Š RÃ©partition des donnÃ©es :\\n\")\n",
    "\n",
    "for split in splits:\n",
    "    img_dir = os.path.join(dataset_path, split, \"images\")\n",
    "    if os.path.isdir(img_dir):\n",
    "        num_images = len([f for f in os.listdir(img_dir) if f.lower().endswith(extensions)])\n",
    "        print(f\"{split} : {num_images} images\")\n",
    "    else:\n",
    "        print(f\"{split} : dossier non trouvÃ©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281fe963",
   "metadata": {},
   "source": [
    "## 5. EntraÃ®nement du modÃ¨le YOLOv9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4f1b994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.230 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.229  Python-3.11.9 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce GTX 1050 Ti with Max-Q Design, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=dataset_detection_poubelle\\data.yaml, degrees=10, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.1, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.2, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=poubelle_pleine_vide7, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=50, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=D:\\Cours\\Master 2\\Deep Learning\\Exercice\\Poubelles\\runs\\detect\\poubelle_pleine_vide7, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=2.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2116822  ultralytics.nn.modules.head.Detect           [2, [128, 256, 512]]          \n",
      "Model summary: 129 layers, 11,136,374 parameters, 11,136,358 gradients, 28.6 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.30.1 ms, read: 16.65.2 MB/s, size: 10.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\Cours\\Master 2\\Deep Learning\\Exercice\\Poubelles\\dataset_detection_poubelle\\train\\labels.cache... 226 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 226/226 112.5Kit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 41.019.1 MB/s, size: 11.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Cours\\Master 2\\Deep Learning\\Exercice\\Poubelles\\dataset_detection_poubelle\\valid\\labels.cache... 32 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 10.7Kit/s 0.0s\n",
      "Plotting labels to D:\\Cours\\Master 2\\Deep Learning\\Exercice\\Poubelles\\runs\\detect\\poubelle_pleine_vide7\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mD:\\Cours\\Master 2\\Deep Learning\\Exercice\\Poubelles\\runs\\detect\\poubelle_pleine_vide7\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/50      2.17G      1.864      3.058      2.267          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 29/29 1.2s/it 35.4s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.0it/s 1.0s1.7s\n",
      "                   all         32         38      0.288      0.509      0.341      0.108\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/50      2.37G      1.659      2.268      2.016         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 29/29 1.4it/s 20.8s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6it/s 1.2s1.9s\n",
      "                   all         32         38      0.275      0.526      0.328      0.115\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/50      2.39G      1.744      2.192      2.072          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 29/29 1.3it/s 23.2s0.6ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.7it/s 1.2s1.9s\n",
      "                   all         32         38      0.326      0.468      0.239     0.0887\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/50      2.22G      1.762      2.064      2.078          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 29/29 1.1it/s 26.3s0.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5it/s 1.3s2.2s\n",
      "                   all         32         38      0.144      0.386     0.0431     0.0159\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/50      2.39G      1.734      1.972      2.042          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 29/29 1.0it/s 28.7s0.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5it/s 1.3s2.2s\n",
      "                   all         32         38      0.179      0.409      0.151     0.0297\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/50      2.39G      1.747      2.024      2.066          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 29/29 1.0it/s 28.5s0.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5it/s 1.3s2.2s\n",
      "                   all         32         38     0.0795       0.08     0.0285    0.00959\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/50      2.28G      1.662      1.916      2.003          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 29/29 1.0it/s 28.7s0.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4it/s 1.4s2.4s\n",
      "                   all         32         38      0.348      0.374      0.266     0.0975\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/50      2.57G      1.641      1.932      1.966          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 29/29 1.0it/s 28.7s0.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5it/s 1.3s2.2s\n",
      "                   all         32         38      0.186      0.115      0.074     0.0352\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/50      2.39G      1.623      1.866      1.948          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 29/29 1.0it/s 28.9s0.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4it/s 1.4s2.3s\n",
      "                   all         32         38       0.38      0.389      0.423       0.19\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/50      2.24G      1.686      1.921      1.988          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 29/29 1.0it/s 28.5s0.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5it/s 1.3s2.2s\n",
      "                   all         32         38     0.0199     0.0585    0.00924    0.00212\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/50      2.27G      1.606      1.819      1.952          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 29/29 1.0it/s 28.8s0.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5it/s 1.3s2.2s\n",
      "                   all         32         38      0.674      0.545      0.636      0.263\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/50       2.2G      1.585      1.763      1.922          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 29/29 1.0it/s 28.6s0.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5it/s 1.3s2.2s\n",
      "                   all         32         38      0.431       0.57      0.484      0.179\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/50      2.23G       1.59       1.73      1.902          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 29/29 1.0it/s 28.7s0.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5it/s 1.3s2.3s\n",
      "                   all         32         38      0.644      0.569      0.656      0.226\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/50      2.23G      1.578      1.651      1.871          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 29/29 1.0it/s 28.9s0.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4it/s 1.4s2.3s\n",
      "                   all         32         38      0.716      0.585      0.674      0.312\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/50      2.21G      1.565      1.745      1.909          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 29/29 1.0it/s 29.0s0.8ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3it/s 1.5s2.2s\n",
      "                   all         32         38      0.881      0.713      0.815      0.319\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/50      2.56G      1.563      1.657      1.898          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 29/29 1.0it/s 28.6s0.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5it/s 1.3s2.3s\n",
      "                   all         32         38      0.812      0.822       0.86      0.366\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/50      2.35G      1.513      1.662      1.846          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 29/29 1.0s/it 29.8s0.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4it/s 1.4s2.3s\n",
      "                   all         32         38      0.849      0.702      0.736      0.308\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/50      2.34G      1.496      1.556      1.803          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 29/29 1.0it/s 28.3s0.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4it/s 1.4s2.2s\n",
      "                   all         32         38      0.735      0.742      0.809      0.399\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/50      2.34G      1.509       1.55      1.826          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 29/29 1.0it/s 28.8s0.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5it/s 1.4s2.3s\n",
      "                   all         32         38      0.776      0.863      0.825      0.353\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/50      2.38G      1.497      1.635      1.856          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 29/29 1.0it/s 28.6s0.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4it/s 1.4s2.5s\n",
      "                   all         32         38       0.74      0.528      0.686      0.368\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      21/50       2.4G      1.489      1.594      1.833          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 29/29 1.0it/s 28.7s0.8ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4it/s 1.4s2.5s\n",
      "                   all         32         38      0.849      0.783      0.849      0.448\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      22/50      2.23G      1.379      1.573       1.78         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 29/29 1.0it/s 28.6s0.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5it/s 1.3s2.2s\n",
      "                   all         32         38      0.838      0.802       0.89      0.377\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      23/50      2.23G      1.455      1.522      1.819          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 29/29 1.0it/s 28.5s0.8ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4it/s 1.5s2.5s\n",
      "                   all         32         38      0.888      0.747      0.857      0.391\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      24/50      2.37G      1.399      1.462      1.764          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 29/29 1.0it/s 28.7s0.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5it/s 1.3s2.2s\n",
      "                   all         32         38      0.949      0.673      0.857      0.426\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      25/50      2.39G      1.377      1.482      1.737         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 29/29 1.0it/s 28.7s0.8ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.7s2.4s\n",
      "                   all         32         38      0.899      0.663      0.871      0.453\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      26/50      2.28G      1.406       1.47      1.763          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 29/29 1.0it/s 28.5s0.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5it/s 1.3s2.3s\n",
      "                   all         32         38      0.723      0.902      0.898       0.43\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      27/50      2.36G      1.392      1.465      1.757          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 29/29 1.0it/s 28.7s0.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5it/s 1.3s2.2s\n",
      "                   all         32         38      0.853      0.815      0.863      0.432\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      28/50      2.26G      1.358      1.416      1.709          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 29/29 1.0it/s 28.7s0.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5it/s 1.3s2.2s\n",
      "                   all         32         38      0.884      0.823      0.877      0.462\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      29/50      2.39G      1.374      1.398      1.765          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 29/29 1.0it/s 28.5s0.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4it/s 1.4s2.3s\n",
      "                   all         32         38      0.872      0.858      0.908      0.503\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      30/50      2.23G      1.374      1.427      1.748         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 29/29 1.0it/s 28.7s0.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4it/s 1.4s2.3s\n",
      "                   all         32         38      0.898      0.875      0.889      0.342\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      31/50      2.53G      1.341      1.361      1.688          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 29/29 1.0it/s 28.4s0.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5it/s 1.3s2.2s\n",
      "                   all         32         38      0.791      0.858      0.896      0.444\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      32/50       2.4G      1.373      1.366      1.728          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 29/29 1.0it/s 28.6s0.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5it/s 1.3s2.2s\n",
      "                   all         32         38      0.884      0.803      0.906      0.423\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      33/50      2.27G      1.303      1.354      1.677          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 29/29 1.0it/s 28.5s0.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5it/s 1.3s2.1s\n",
      "                   all         32         38      0.882      0.843      0.914      0.471\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      34/50      2.23G      1.288      1.299       1.67          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 29/29 1.0it/s 28.7s0.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5it/s 1.3s2.2s\n",
      "                   all         32         38      0.942      0.882      0.919      0.447\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      35/50      2.42G      1.343      1.384      1.709          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 29/29 1.0it/s 28.4s0.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4it/s 1.4s2.3s\n",
      "                   all         32         38      0.878      0.879      0.898      0.452\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      36/50      2.27G      1.374      1.381      1.737          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 29/29 1.0it/s 28.7s0.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5it/s 1.3s2.2s\n",
      "                   all         32         38      0.842      0.902      0.895      0.482\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      37/50       2.4G      1.263      1.295      1.645          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 29/29 1.0it/s 28.5s0.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5it/s 1.3s2.3s\n",
      "                   all         32         38       0.88       0.84      0.883       0.46\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      38/50      2.36G      1.293        1.3       1.67         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 29/29 1.0it/s 28.8s0.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4it/s 1.4s2.3s\n",
      "                   all         32         38      0.945      0.843      0.898      0.478\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      39/50      2.39G      1.271      1.261      1.648          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 29/29 1.0it/s 28.6s0.8ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5it/s 1.4s2.4s\n",
      "                   all         32         38      0.878      0.834      0.893      0.466\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      40/50      2.25G       1.28      1.281      1.655         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 29/29 1.0it/s 28.5s0.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4it/s 1.4s2.4s\n",
      "                   all         32         38      0.859      0.814      0.915       0.48\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      41/50      2.23G      1.111      1.123       1.71          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 29/29 1.0s/it 29.3s0.6ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5it/s 1.3s2.2s\n",
      "                   all         32         38      0.864      0.882      0.919      0.479\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      42/50      2.22G      1.007     0.8898      1.618          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 29/29 1.0it/s 27.9s0.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5it/s 1.3s2.3s\n",
      "                   all         32         38      0.861      0.857      0.897      0.486\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      43/50      2.16G      0.965     0.7714      1.637          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 29/29 1.0it/s 28.2s0.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5it/s 1.3s2.2s\n",
      "                   all         32         38      0.891      0.913      0.922      0.518\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      44/50      2.46G     0.9726     0.7917      1.584          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 29/29 1.0it/s 28.2s0.6ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5it/s 1.4s2.3s\n",
      "                   all         32         38      0.895      0.883      0.904      0.482\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      45/50      2.23G      1.045     0.7871       1.66          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 29/29 1.0it/s 28.3s0.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5it/s 1.3s2.2s\n",
      "                   all         32         38      0.898      0.882      0.897      0.528\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      46/50      2.24G     0.9315     0.7199      1.564          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 29/29 1.0it/s 28.2s0.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5it/s 1.3s2.2s\n",
      "                   all         32         38      0.898      0.882      0.907      0.544\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      47/50      2.24G     0.9151     0.7051      1.549          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 29/29 1.0it/s 28.4s0.8ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5it/s 1.3s2.2s\n",
      "                   all         32         38      0.877      0.875      0.907      0.548\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      48/50      2.39G     0.9599     0.7197      1.594          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 29/29 1.0it/s 28.1s0.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5it/s 1.3s2.2s\n",
      "                   all         32         38      0.931      0.823      0.904      0.549\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      49/50      2.36G     0.9456     0.7147      1.549          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 29/29 1.0it/s 28.2s0.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4it/s 1.5s2.6s\n",
      "                   all         32         38      0.853      0.885      0.908      0.563\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      50/50       2.4G     0.9301     0.6684      1.537          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 29/29 1.0it/s 28.6s0.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5it/s 1.3s2.2s\n",
      "                   all         32         38      0.855      0.895      0.912      0.571\n",
      "\n",
      "50 epochs completed in 0.447 hours.\n",
      "Optimizer stripped from D:\\Cours\\Master 2\\Deep Learning\\Exercice\\Poubelles\\runs\\detect\\poubelle_pleine_vide7\\weights\\last.pt, 22.5MB\n",
      "Optimizer stripped from D:\\Cours\\Master 2\\Deep Learning\\Exercice\\Poubelles\\runs\\detect\\poubelle_pleine_vide7\\weights\\best.pt, 22.5MB\n",
      "\n",
      "Validating D:\\Cours\\Master 2\\Deep Learning\\Exercice\\Poubelles\\runs\\detect\\poubelle_pleine_vide7\\weights\\best.pt...\n",
      "Ultralytics 8.3.229  Python-3.11.9 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce GTX 1050 Ti with Max-Q Design, 4096MiB)\n",
      "Model summary (fused): 72 layers, 11,126,358 parameters, 0 gradients, 28.4 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.8s3.2s\n",
      "                   all         32         38      0.855      0.895      0.912      0.571\n",
      "       poubelle_pleine         19         25      0.855       0.88      0.909      0.466\n",
      "         poubelle_vide         13         13      0.855       0.91      0.915      0.676\n",
      "Speed: 7.6ms preprocess, 32.2ms inference, 0.0ms loss, 5.4ms postprocess per image\n",
      "Results saved to \u001b[1mD:\\Cours\\Master 2\\Deep Learning\\Exercice\\Poubelles\\runs\\detect\\poubelle_pleine_vide7\u001b[0m\n",
      "DurÃ©e totale : 28.0 min\n"
     ]
    }
   ],
   "source": [
    "# Charger modÃ¨le lÃ©ger pour petit dataset\n",
    "model = YOLO(\"yolov8s.pt\")   # ou \"yolov9s.pt\"\n",
    "\n",
    "start_time = time.time()\n",
    "results = model.train(\n",
    "    data=data_yaml,\n",
    "    epochs=50,        \n",
    "    imgsz=640,\n",
    "    batch=8,          \n",
    "    patience=50,      \n",
    "    hsv_h=0.015,\n",
    "    hsv_s=0.7,\n",
    "    hsv_v=0.4,\n",
    "    degrees=10,\n",
    "    translate=0.1,\n",
    "    scale=0.5,\n",
    "    shear=2.0,\n",
    "    flipud=0.1,\n",
    "    fliplr=0.5,\n",
    "    mosaic=1.0,\n",
    "    mixup=0.2,\n",
    "    name=\"poubelle_pleine_vide\",\n",
    "    save=True,\n",
    "    plots=True\n",
    ")\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"DurÃ©e totale : {(end_time - start_time)/60:.1f} min\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7232ea80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fin de l'entraÃ®nement: 2025-11-22 02:16:15\n",
      "Temps total d'entraÃ®nement: 0h 27m 58s\n",
      "Temps en secondes: 1678.45s\n"
     ]
    }
   ],
   "source": [
    "training_time = end_time - start_time\n",
    "training_hours = int(training_time // 3600)\n",
    "training_minutes = int((training_time % 3600) // 60)\n",
    "training_seconds = int(training_time % 60)\n",
    "\n",
    "print(f\"Temps total d'entraÃ®nement: {training_hours}h {training_minutes}m {training_seconds}s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0531d89c",
   "metadata": {},
   "source": [
    "## 6. Courbes d'apprentissage (Loss et MÃ©triques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fed766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x1200 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Charger les rÃ©sultats d'entraÃ®nement depuis le fichier CSV\n",
    "results_csv = 'runs/detect/poubelle_pleine_vide7/results.csv'\n",
    "\n",
    "# Lire les rÃ©sultats\n",
    "df_results = pd.read_csv(results_csv)\n",
    "df_results.columns = df_results.columns.str.strip()  # Nettoyer les noms de colonnes\n",
    "\n",
    "# CrÃ©er une figure avec plusieurs sous-graphiques\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Courbes d\\'apprentissage - YOLOv9 DÃ©tection de Poubelles', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Loss (Train & Val)\n",
    "ax1 = axes[0, 0]\n",
    "if 'train/box_loss' in df_results.columns:\n",
    "    ax1.plot(df_results['epoch'], df_results['train/box_loss'], label='Train Box Loss', linewidth=2)\n",
    "if 'val/box_loss' in df_results.columns:\n",
    "    ax1.plot(df_results['epoch'], df_results['val/box_loss'], label='Val Box Loss', linewidth=2)\n",
    "ax1.set_xlabel('Epoch', fontsize=12)\n",
    "ax1.set_ylabel('Loss', fontsize=12)\n",
    "ax1.set_title('Box Loss (Train vs Validation)', fontsize=13, fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Precision & Recall\n",
    "ax2 = axes[0, 1]\n",
    "if 'metrics/precision(B)' in df_results.columns:\n",
    "    ax2.plot(df_results['epoch'], df_results['metrics/precision(B)'], label='Precision', linewidth=2, color='green')\n",
    "if 'metrics/recall(B)' in df_results.columns:\n",
    "    ax2.plot(df_results['epoch'], df_results['metrics/recall(B)'], label='Recall', linewidth=2, color='orange')\n",
    "ax2.set_xlabel('Epoch', fontsize=12)\n",
    "ax2.set_ylabel('Score', fontsize=12)\n",
    "ax2.set_title('Precision & Recall', fontsize=13, fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_ylim([0, 1])\n",
    "\n",
    "# 3. mAP50 & mAP50-95\n",
    "ax3 = axes[1, 0]\n",
    "if 'metrics/mAP50(B)' in df_results.columns:\n",
    "    ax3.plot(df_results['epoch'], df_results['metrics/mAP50(B)'], label='mAP@50', linewidth=2, color='blue')\n",
    "if 'metrics/mAP50-95(B)' in df_results.columns:\n",
    "    ax3.plot(df_results['epoch'], df_results['metrics/mAP50-95(B)'], label='mAP@50-95', linewidth=2, color='red')\n",
    "ax3.set_xlabel('Epoch', fontsize=12)\n",
    "ax3.set_ylabel('mAP', fontsize=12)\n",
    "ax3.set_title('Mean Average Precision', fontsize=13, fontweight='bold')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.set_ylim([0, 1])\n",
    "\n",
    "# 4. All Losses Combined\n",
    "ax4 = axes[1, 1]\n",
    "if 'train/box_loss' in df_results.columns:\n",
    "    ax4.plot(df_results['epoch'], df_results['train/box_loss'], label='Box Loss', linewidth=2)\n",
    "if 'train/cls_loss' in df_results.columns:\n",
    "    ax4.plot(df_results['epoch'], df_results['train/cls_loss'], label='Class Loss', linewidth=2)\n",
    "if 'train/dfl_loss' in df_results.columns:\n",
    "    ax4.plot(df_results['epoch'], df_results['train/dfl_loss'], label='DFL Loss', linewidth=2)\n",
    "ax4.set_xlabel('Epoch', fontsize=12)\n",
    "ax4.set_ylabel('Loss', fontsize=12)\n",
    "ax4.set_title('Toutes les Loss d\\'entraÃ®nement', fontsize=13, fontweight='bold')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "48955381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STATISTIQUES FINALES D'ENTRAÃNEMENT\n",
      "============================================================\n",
      "\n",
      "Ã‰poque finale: 50\n",
      "mAP@50: 0.9119\n",
      "mAP@50-95: 0.5706\n",
      "Precision: 0.8552\n",
      "Recall: 0.8947\n"
     ]
    }
   ],
   "source": [
    "# Afficher les statistiques finales\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STATISTIQUES FINALES D'ENTRAÃNEMENT\")\n",
    "print(\"=\"*60)\n",
    "last_epoch = df_results.iloc[-1]\n",
    "print(f\"\\nÃ‰poque finale: {int(last_epoch['epoch'])}\")\n",
    "if 'metrics/mAP50(B)' in df_results.columns:\n",
    "    print(f\"mAP@50: {last_epoch['metrics/mAP50(B)']:.4f}\")\n",
    "if 'metrics/mAP50-95(B)' in df_results.columns:\n",
    "    print(f\"mAP@50-95: {last_epoch['metrics/mAP50-95(B)']:.4f}\")\n",
    "if 'metrics/precision(B)' in df_results.columns:\n",
    "    print(f\"Precision: {last_epoch['metrics/precision(B)']:.4f}\")\n",
    "if 'metrics/recall(B)' in df_results.columns:\n",
    "    print(f\"Recall: {last_epoch['metrics/recall(B)']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda7e6d6",
   "metadata": {},
   "source": [
    "## 7. Ã‰valuation du modÃ¨le sur l'ensemble de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a26678ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ã‰valuation du modÃ¨le sur l'ensemble de validation...\n",
      "Ultralytics 8.3.229  Python-3.11.9 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce GTX 1050 Ti with Max-Q Design, 4096MiB)\n",
      "Model summary (fused): 72 layers, 11,126,358 parameters, 0 gradients, 28.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 118.927.3 MB/s, size: 13.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Cours\\Master 2\\Deep Learning\\Exercice\\Poubelles\\dataset_detection_poubelle\\valid\\labels.cache... 32 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 32.0Kit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.6s/it 5.2s<12.8s\n",
      "                   all         32         38      0.855      0.894      0.912      0.571\n",
      "       poubelle_pleine         19         25      0.855       0.88      0.909      0.466\n",
      "         poubelle_vide         13         13      0.855      0.909      0.915      0.676\n",
      "Speed: 6.0ms preprocess, 22.6ms inference, 0.0ms loss, 15.7ms postprocess per image\n",
      "Results saved to \u001b[1mD:\\Cours\\Master 2\\Deep Learning\\Exercice\\Poubelles\\runs\\detect\\val\u001b[0m\n",
      "\n",
      "============================================================\n",
      "MÃ‰TRIQUES D'Ã‰VALUATION\n",
      "============================================================\n",
      "\n",
      "mAP@50: 0.9121\n",
      "mAP@50-95: 0.5707\n",
      "PrÃ©cision: 0.8550\n",
      "Rappel: 0.8945\n",
      "F1-Score: 0.8743\n",
      "\n",
      "============================================================\n",
      "MÃ‰TRIQUES PAR CLASSE\n",
      "============================================================\n",
      "\n",
      "Classe: poubelle_pleine\n",
      "  AP@50: 0.9090\n",
      "  AP@50-95: 0.4658\n",
      "\n",
      "Classe: poubelle_vide\n",
      "  AP@50: 0.9151\n",
      "  AP@50-95: 0.6756\n"
     ]
    }
   ],
   "source": [
    "# Charger le meilleur modÃ¨le\n",
    "best_model = YOLO('runs/detect/poubelle_pleine_vide7/weights/best.pt')\n",
    "\n",
    "# Ã‰valuer le modÃ¨le sur l'ensemble de validation\n",
    "print(\"Ã‰valuation du modÃ¨le sur l'ensemble de validation...\")\n",
    "metrics = best_model.val()\n",
    "\n",
    "# Afficher les mÃ©triques dÃ©taillÃ©es\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MÃ‰TRIQUES D'Ã‰VALUATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nmAP@50: {metrics.box.map50:.4f}\")\n",
    "print(f\"mAP@50-95: {metrics.box.map:.4f}\")\n",
    "print(f\"PrÃ©cision: {metrics.box.mp:.4f}\")\n",
    "print(f\"Rappel: {metrics.box.mr:.4f}\")\n",
    "print(f\"F1-Score: {2 * (metrics.box.mp * metrics.box.mr) / (metrics.box.mp + metrics.box.mr + 1e-6):.4f}\")\n",
    "\n",
    "# Afficher les mÃ©triques par classe\n",
    "if hasattr(metrics.box, 'ap_class_index'):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"MÃ‰TRIQUES PAR CLASSE\")\n",
    "    print(f\"{'='*60}\")\n",
    "    for i, class_idx in enumerate(metrics.box.ap_class_index):\n",
    "        class_name = best_model.names[int(class_idx)]\n",
    "        print(f\"\\nClasse: {class_name}\")\n",
    "        if hasattr(metrics.box, 'ap'):\n",
    "            print(f\"  AP@50: {metrics.box.ap50[i]:.4f}\")\n",
    "            print(f\"  AP@50-95: {metrics.box.ap[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c61b2d",
   "metadata": {},
   "source": [
    "## 8. Matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c0b3e961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GÃ©nÃ©ration de la matrice de confusion...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RAPPORT DE CLASSIFICATION\n",
      "============================================================\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "poubelle_pleine       1.00      1.00      1.00        23\n",
      "  poubelle_vide       1.00      1.00      1.00        13\n",
      "\n",
      "       accuracy                           1.00        36\n",
      "      macro avg       1.00      1.00      1.00        36\n",
      "   weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "\n",
      "Accuracy globale: 1.0000 (100.00%)\n"
     ]
    }
   ],
   "source": [
    "# GÃ©nÃ©rer des prÃ©dictions sur l'ensemble de validation pour la matrice de confusion\n",
    "val_images_path = os.path.join(dataset_path, 'valid', 'images')\n",
    "val_labels_path = os.path.join(dataset_path, 'valid', 'labels')\n",
    "\n",
    "# Lire les annotations de validation\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "print(\"GÃ©nÃ©ration de la matrice de confusion...\")\n",
    "\n",
    "# Parcourir les images de validation\n",
    "if os.path.exists(val_images_path):\n",
    "    image_files = [f for f in os.listdir(val_images_path) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    \n",
    "    for img_file in image_files:\n",
    "        img_path = os.path.join(val_images_path, img_file)\n",
    "        label_file = os.path.splitext(img_file)[0] + '.txt'\n",
    "        label_path = os.path.join(val_labels_path, label_file)\n",
    "        \n",
    "        # PrÃ©diction\n",
    "        results = best_model.predict(img_path, verbose=False)\n",
    "        \n",
    "        # Lire les vraies Ã©tiquettes\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    true_class = int(line.strip().split()[0])\n",
    "                    y_true.append(true_class)\n",
    "                    \n",
    "                    # Trouver la prÃ©diction correspondante\n",
    "                    if len(results[0].boxes) > 0:\n",
    "                        pred_class = int(results[0].boxes.cls[0].item())\n",
    "                        y_pred.append(pred_class)\n",
    "                    else:\n",
    "                        # Aucune dÃ©tection - classe \"background\" ou -1\n",
    "                        y_pred.append(-1)\n",
    "\n",
    "# CrÃ©er la matrice de confusion\n",
    "if len(y_true) > 0 and len(y_pred) > 0:\n",
    "    # Filtrer les prÃ©dictions sans dÃ©tection (-1)\n",
    "    valid_indices = [i for i, pred in enumerate(y_pred) if pred != -1]\n",
    "    y_true_filtered = [y_true[i] for i in valid_indices]\n",
    "    y_pred_filtered = [y_pred[i] for i in valid_indices]\n",
    "    \n",
    "    if len(y_true_filtered) > 0:\n",
    "        # Calculer la matrice de confusion\n",
    "        cm = confusion_matrix(y_true_filtered, y_pred_filtered)\n",
    "        \n",
    "        # Obtenir les noms de classes\n",
    "        class_names = [best_model.names[i] for i in sorted(set(y_true_filtered + y_pred_filtered))]\n",
    "        \n",
    "        # Afficher la matrice de confusion\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                    xticklabels=class_names, \n",
    "                    yticklabels=class_names,\n",
    "                    cbar_kws={'label': 'Nombre de prÃ©dictions'})\n",
    "        plt.title('Matrice de Confusion - DÃ©tection de Poubelles', fontsize=14, fontweight='bold')\n",
    "        plt.ylabel('Vraie Classe', fontsize=12)\n",
    "        plt.xlabel('Classe PrÃ©dite', fontsize=12)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Rapport de classification\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"RAPPORT DE CLASSIFICATION\")\n",
    "        print(\"=\"*60)\n",
    "        print(classification_report(y_true_filtered, y_pred_filtered, \n",
    "                                   target_names=class_names, \n",
    "                                   zero_division=0))\n",
    "        \n",
    "        # Calcul de l'accuracy\n",
    "        accuracy = np.sum(np.array(y_true_filtered) == np.array(y_pred_filtered)) / len(y_true_filtered)\n",
    "        print(f\"\\nAccuracy globale: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    else:\n",
    "        print(\"Aucune prÃ©diction valide trouvÃ©e pour gÃ©nÃ©rer la matrice de confusion.\")\n",
    "else:\n",
    "    print(\"Impossible de gÃ©nÃ©rer la matrice de confusion - donnÃ©es insuffisantes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae9b13f",
   "metadata": {},
   "source": [
    "## 9. Analyse des rÃ©sultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0056a9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\" \"*25 + \"ANALYSE COMPLÃˆTE DES RÃ‰SULTATS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. RÃ©sumÃ© de l'entraÃ®nement\n",
    "print(\"\\nğŸ“Š 1. RÃ‰SUMÃ‰ DE L'ENTRAÃNEMENT\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"Temps d'entraÃ®nement: {training_hours}h {training_minutes}m {training_seconds}s\")\n",
    "print(f\"Architecture: YOLOv9c\")\n",
    "print(f\"Taille d'image: 640x640\")\n",
    "print(f\"Batch size: 16\")\n",
    "\n",
    "# 2. Performance du modÃ¨le\n",
    "print(\"\\nğŸ“ˆ 2. PERFORMANCE DU MODÃˆLE\")\n",
    "print(\"-\" * 80)\n",
    "if 'metrics' in locals():\n",
    "    print(f\"mAP@50: {metrics.box.map50:.4f} ({metrics.box.map50*100:.2f}%)\")\n",
    "    print(f\"mAP@50-95: {metrics.box.map:.4f} ({metrics.box.map*100:.2f}%)\")\n",
    "    print(f\"PrÃ©cision: {metrics.box.mp:.4f} ({metrics.box.mp*100:.2f}%)\")\n",
    "    print(f\"Rappel: {metrics.box.mr:.4f} ({metrics.box.mr*100:.2f}%)\")\n",
    "    f1 = 2 * (metrics.box.mp * metrics.box.mr) / (metrics.box.mp + metrics.box.mr + 1e-6)\n",
    "    print(f\"F1-Score: {f1:.4f} ({f1*100:.2f}%)\")\n",
    "\n",
    "# 3. InterprÃ©tation des rÃ©sultats\n",
    "print(\"\\nğŸ’¡ 3. INTERPRÃ‰TATION DES RÃ‰SULTATS\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "if 'metrics' in locals():\n",
    "    # InterprÃ©tation du mAP\n",
    "    if metrics.box.map50 > 0.9:\n",
    "        print(\"âœ… Excellent mAP@50 (>90%) - Le modÃ¨le dÃ©tecte trÃ¨s bien les poubelles\")\n",
    "    elif metrics.box.map50 > 0.7:\n",
    "        print(\"âœ“ Bon mAP@50 (70-90%) - Performance satisfaisante\")\n",
    "    elif metrics.box.map50 > 0.5:\n",
    "        print(\"âš  mAP@50 moyen (50-70%) - Des amÃ©liorations sont possibles\")\n",
    "    else:\n",
    "        print(\"âŒ mAP@50 faible (<50%) - Le modÃ¨le nÃ©cessite des amÃ©liorations\")\n",
    "    \n",
    "    # InterprÃ©tation PrÃ©cision vs Rappel\n",
    "    if metrics.box.mp > metrics.box.mr:\n",
    "        print(f\"\\nğŸ“ PrÃ©cision > Rappel: Le modÃ¨le est conservateur\")\n",
    "        print(\"   â†’ Peu de faux positifs, mais peut manquer certaines dÃ©tections\")\n",
    "    elif metrics.box.mr > metrics.box.mp:\n",
    "        print(f\"\\nğŸ“ Rappel > PrÃ©cision: Le modÃ¨le est permissif\")\n",
    "        print(\"   â†’ DÃ©tecte beaucoup de poubelles, mais avec quelques faux positifs\")\n",
    "    else:\n",
    "        print(f\"\\nğŸ“ PrÃ©cision â‰ˆ Rappel: ModÃ¨le Ã©quilibrÃ©\")\n",
    "\n",
    "# 4. Recommandations\n",
    "print(\"\\nğŸ¯ 4. RECOMMANDATIONS\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "if 'metrics' in locals():\n",
    "    if metrics.box.map50 < 0.7:\n",
    "        print(\"â€¢ Augmenter le nombre d'Ã©poques d'entraÃ®nement\")\n",
    "        print(\"â€¢ Utiliser l'augmentation de donnÃ©es (data augmentation)\")\n",
    "        print(\"â€¢ Collecter plus d'images d'entraÃ®nement variÃ©es\")\n",
    "        print(\"â€¢ Essayer un modÃ¨le plus grand (yolov9e)\")\n",
    "    \n",
    "    if metrics.box.mp < 0.7:\n",
    "        print(\"â€¢ Ajuster le seuil de confiance pour rÃ©duire les faux positifs\")\n",
    "        print(\"â€¢ VÃ©rifier la qualitÃ© des annotations\")\n",
    "    \n",
    "    if metrics.box.mr < 0.7:\n",
    "        print(\"â€¢ RÃ©duire le seuil de confiance pour dÃ©tecter plus d'objets\")\n",
    "        print(\"â€¢ Ajouter plus d'exemples de poubelles difficiles Ã  dÃ©tecter\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38af93b2",
   "metadata": {},
   "source": [
    "## 10. Visualisation des graphiques d'entraÃ®nement (gÃ©nÃ©rÃ©s par YOLO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88552c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les graphiques gÃ©nÃ©rÃ©s automatiquement par YOLO\n",
    "results_dir = 'runs/detect/poubelle_detection'\n",
    "\n",
    "# Liste des graphiques Ã  afficher\n",
    "plot_files = [\n",
    "    'results.png',\n",
    "    'confusion_matrix.png',\n",
    "    'PR_curve.png',\n",
    "    'F1_curve.png'\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 14))\n",
    "fig.suptitle('Graphiques d\\'EntraÃ®nement YOLOv9', fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, (ax, plot_file) in enumerate(zip(axes.flat, plot_files)):\n",
    "    plot_path = os.path.join(results_dir, plot_file)\n",
    "    \n",
    "    if os.path.exists(plot_path):\n",
    "        img = cv2.imread(plot_path)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        ax.imshow(img_rgb)\n",
    "        ax.axis('off')\n",
    "        ax.set_title(plot_file.replace('.png', '').replace('_', ' ').title(), \n",
    "                    fontsize=12, fontweight='bold')\n",
    "    else:\n",
    "        ax.text(0.5, 0.5, f'{plot_file}\\nnon disponible', \n",
    "               ha='center', va='center', fontsize=12)\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nâœ… Tous les graphiques sont disponibles dans: {results_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134a4634",
   "metadata": {},
   "source": [
    "## 11. PrÃ©diction sur de nouvelles images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3483d35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faire des prÃ©dictions sur des images de test\n",
    "test_images_path = os.path.join(dataset_path, 'test', 'images')\n",
    "results = best_model.predict(source=test_images_path, save=True, conf=0.5)\n",
    "\n",
    "print(f\"PrÃ©dictions sauvegardÃ©es dans: runs/detect/predict/\")\n",
    "print(f\"Nombre d'images testÃ©es: {len(results)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb35767",
   "metadata": {},
   "source": [
    "## 12. Visualisation des prÃ©dictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1dcc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour afficher quelques prÃ©dictions\n",
    "def afficher_predictions(results, num_images=5):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    for i, result in enumerate(results[:num_images]):\n",
    "        # RÃ©cupÃ©rer l'image avec les boÃ®tes de dÃ©tection\n",
    "        img = result.plot()\n",
    "        \n",
    "        # Convertir BGR to RGB pour matplotlib\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        plt.subplot(2, 3, i+1)\n",
    "        plt.imshow(img_rgb)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Afficher les classes dÃ©tectÃ©es\n",
    "        if len(result.boxes) > 0:\n",
    "            classes = result.boxes.cls.cpu().numpy()\n",
    "            names = [result.names[int(c)] for c in classes]\n",
    "            plt.title(f\"DÃ©tectÃ©: {', '.join(set(names))}\")\n",
    "        else:\n",
    "            plt.title(\"Aucune dÃ©tection\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Afficher les prÃ©dictions\n",
    "afficher_predictions(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a3edb1",
   "metadata": {},
   "source": [
    "## 13. Fonction de prÃ©diction sur une image unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c144b883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predire_poubelle(image_path, model):\n",
    "    \"\"\"\n",
    "    PrÃ©dire si une poubelle est pleine ou vide\n",
    "    \n",
    "    Args:\n",
    "        image_path: Chemin vers l'image Ã  analyser\n",
    "        model: ModÃ¨le YOLO entraÃ®nÃ©\n",
    "    \n",
    "    Returns:\n",
    "        dict: RÃ©sultats de la prÃ©diction\n",
    "    \"\"\"\n",
    "    results = model.predict(source=image_path, conf=0.5)\n",
    "    \n",
    "    predictions = []\n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            class_id = int(box.cls)\n",
    "            class_name = result.names[class_id]\n",
    "            confidence = float(box.conf)\n",
    "            \n",
    "            predictions.append({\n",
    "                'classe': class_name,\n",
    "                'confiance': confidence,\n",
    "                'bbox': box.xyxy.cpu().numpy()[0]\n",
    "            })\n",
    "    \n",
    "    # Afficher l'image avec les dÃ©tections\n",
    "    img = results[0].plot()\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"DÃ©tections: {len(predictions)}\")\n",
    "    plt.show()\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Exemple d'utilisation\n",
    "# image_test = \"chemin/vers/votre/image.jpg\"\n",
    "# predictions = predire_poubelle(image_test, best_model)\n",
    "# for pred in predictions:\n",
    "#     print(f\"Classe: {pred['classe']}, Confiance: {pred['confiance']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7302ea",
   "metadata": {},
   "source": [
    "## 14. Sauvegarde et export du modÃ¨le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4588026a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Le modÃ¨le est dÃ©jÃ  sauvegardÃ© dans runs/detect/poubelle_detection/weights/best.pt\n",
    "\n",
    "# Export du modÃ¨le vers diffÃ©rents formats (optionnel)\n",
    "# best_model.export(format='onnx')  # Pour ONNX\n",
    "# best_model.export(format='tflite')  # Pour TensorFlow Lite\n",
    "# best_model.export(format='torchscript')  # Pour TorchScript\n",
    "\n",
    "print(\"ModÃ¨le entraÃ®nÃ© disponible Ã : runs/detect/poubelle_detection/weights/best.pt\")\n",
    "print(\"\\nPour utiliser le modÃ¨le plus tard:\")\n",
    "print(\"model = YOLO('runs/detect/poubelle_detection/weights/best.pt')\")\n",
    "print(\"results = model.predict('votre_image.jpg')\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
